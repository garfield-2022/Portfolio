{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c9dc2eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e119c824",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1cb71c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.metrics import PrecisionRecallDisplay\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import RocCurveDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "996c1c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'creditcard.csv'\n",
    "df = pd.read_csv(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9b890ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next we will split the new dataset into Features and Target\n",
    "X = df.drop(columns=\"Class\", axis=1)\n",
    "y = df[\"Class\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9681f697",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(284807, 30)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0426441b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(284807,)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "27e91de6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training sets:\n",
      "X_train: (227845, 30) y_train:(227845,)\n",
      "\n",
      "Testing sets:\n",
      "X_test: (56962, 30) y_test:(56962,)\n"
     ]
    }
   ],
   "source": [
    "# Split the new dataset into training and testing parts\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, stratify=y, random_state=0)\n",
    "\n",
    "print(\"Training sets:\\nX_train: {} y_train:{}\".format(X_train.shape, y_train.shape))\n",
    "print(\"\\nTesting sets:\\nX_test: {} y_test:{}\".format(X_test.shape, y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e7e71e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the scaler on the entire data frame so that it standardizes all of the data in the same way. \n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X)\n",
    "\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acaf9433",
   "metadata": {},
   "source": [
    "# Logistic Regression as generalized linear model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "738a0553",
   "metadata": {},
   "outputs": [],
   "source": [
    "glm = sm.GLM(y_train, X_train, family=sm.families.Binomial())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c095d067",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = glm.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9c8abdd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Generalized Linear Model Regression Results                  \n",
      "==============================================================================\n",
      "Dep. Variable:                  Class   No. Observations:               227845\n",
      "Model:                            GLM   Df Residuals:                   227815\n",
      "Model Family:                Binomial   Df Model:                           29\n",
      "Link Function:                  Logit   Scale:                          1.0000\n",
      "Method:                          IRLS   Log-Likelihood:                -41245.\n",
      "Date:                Mon, 25 Sep 2023   Deviance:                       82490.\n",
      "Time:                        09:48:46   Pearson chi2:                 2.93e+17\n",
      "No. Iterations:                     9   Pseudo R-squ. (CS):            -0.4002\n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "x1            -0.0707      0.008     -8.827      0.000      -0.086      -0.055\n",
      "x2            -7.7428      0.028   -281.295      0.000      -7.797      -7.689\n",
      "x3             6.6142      0.026    256.859      0.000       6.564       6.665\n",
      "x4           -13.4149      0.047   -288.009      0.000     -13.506     -13.324\n",
      "x5             7.3606      0.026    283.560      0.000       7.310       7.411\n",
      "x6            -8.3422      0.030   -276.105      0.000      -8.401      -8.283\n",
      "x7            -2.8370      0.012   -234.070      0.000      -2.861      -2.813\n",
      "x8           -14.3403      0.050   -286.308      0.000     -14.438     -14.242\n",
      "x9             3.3020      0.013    256.220      0.000       3.277       3.327\n",
      "x10           -6.2295      0.022   -281.349      0.000      -6.273      -6.186\n",
      "x11          -14.3176      0.049   -289.694      0.000     -14.414     -14.221\n",
      "x12            9.3841      0.033    286.792      0.000       9.320       9.448\n",
      "x13          -16.5836      0.057   -290.535      0.000     -16.695     -16.472\n",
      "x14            0.1967      0.006     33.357      0.000       0.185       0.208\n",
      "x15          -16.4777      0.057   -290.614      0.000     -16.589     -16.367\n",
      "x16           -0.3526      0.006    -57.242      0.000      -0.365      -0.341\n",
      "x17          -13.6908      0.047   -289.835      0.000     -13.783     -13.598\n",
      "x18          -24.0808      0.083   -291.304      0.000     -24.243     -23.919\n",
      "x19           -8.8440      0.031   -286.491      0.000      -8.904      -8.783\n",
      "x20            2.8097      0.011    247.827      0.000       2.787       2.832\n",
      "x21            1.5041      0.011    140.544      0.000       1.483       1.525\n",
      "x22            1.7180      0.009    201.666      0.000       1.701       1.735\n",
      "x23            0.1628      0.006     26.355      0.000       0.151       0.175\n",
      "x24           -0.1009      0.006    -16.104      0.000      -0.113      -0.089\n",
      "x25           -0.1019      0.006    -17.438      0.000      -0.113      -0.090\n",
      "x26            0.3298      0.007     50.385      0.000       0.317       0.343\n",
      "x27            0.1028      0.006     17.438      0.000       0.091       0.114\n",
      "x28            1.0612      0.007    147.410      0.000       1.047       1.075\n",
      "x29            0.3894      0.006     67.518      0.000       0.378       0.401\n",
      "x30            0.2311      0.020     11.363      0.000       0.191       0.271\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "# Very small p-values suggest that all the 30 features are associated with Class feature.\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d07b0188",
   "metadata": {},
   "source": [
    "# Logistic Regression as the classification algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bbcdcdcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will use the SMOTE sampling technique, because the basic implementation of SMOTE will not make any distinction \n",
    "# between easy and hard samples to be classified using the nearest neighbors rule.\n",
    "# https://imbalanced-learn.org/stable/common_pitfalls.html\n",
    "\n",
    "model = make_pipeline(SMOTE(random_state=0), LogisticRegression())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3513652a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced accuracy mean:0.948\n"
     ]
    }
   ],
   "source": [
    "cv_results = cross_validate(model, X_train, y_train, scoring=\"balanced_accuracy\",\n",
    "    return_train_score=True, return_estimator=True, n_jobs=-1)\n",
    "    \n",
    "print(f\"Balanced accuracy mean:\" f\"{cv_results['test_score'].mean():.3f}\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b15c861",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_scores = []\n",
    "f1_scores = []\n",
    "auc_scores = []\n",
    "\n",
    "for fold_id, cv_model in enumerate(cv_results[\"estimator\"]):\n",
    "    \n",
    "    y_pred = cv_model.predict(X_test)\n",
    "    \n",
    "    accuracy_scores.append(balanced_accuracy_score(y_test, y_pred))\n",
    "    f1_scores.append(f1_score(y_test, y_pred))\n",
    "    \n",
    "    # predict probabilities    \n",
    "    y_probs = cv_model.predict_proba(X_test)\n",
    "    y_probs = y_probs[:, 1]\n",
    "    \n",
    "    precision, recall, thresholds = precision_recall_curve(y_test, y_probs)\n",
    "\n",
    "    auc_scores.append(auc(recall, precision))\n",
    "\n",
    "# summarize scores\n",
    "print(f\"Balanced accuracy mean:\" f\"{np.mean(accuracy_scores):.3f}\")\n",
    "\n",
    "print('Logistic: f1 score=%.3f auc score=%.3f' % (np.mean(f1_scores), np.mean(auc_scores)))    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "539f2a6c",
   "metadata": {},
   "source": [
    "# Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ddfef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tune Hyperparameters for Classification Machine Learning Algorithms \n",
    "# https://machinelearningmastery.com/hyperparameters-for-classification-machine-learning-algorithms/\n",
    "LogisticRegression().get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81078d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#solvers = ['newton-cg', 'lbfgs', 'liblinear']\n",
    "c_values = [100, 10, 1.0, 0.1, 0.01]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9187d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for C in c_values:\n",
    "    \n",
    "    model = make_pipeline(SMOTE(random_state=0), LogisticRegression(C=C))\n",
    "    \n",
    "    cv_results = cross_validate(model, X_train, y_train, scoring=\"balanced_accuracy\",\n",
    "    return_train_score=True, return_estimator=True, n_jobs=-1)\n",
    "    \n",
    "    accuracy_scores = []\n",
    "    f1_scores = []\n",
    "    auc_scores = []\n",
    "\n",
    "    for fold_id, cv_model in enumerate(cv_results[\"estimator\"]):\n",
    "        \n",
    "        y_pred = cv_model.predict(X_test)\n",
    "\n",
    "        accuracy_scores.append(balanced_accuracy_score(y_test, y_pred))\n",
    "        f1_scores.append(f1_score(y_test, y_pred))\n",
    "        \n",
    "        # predict probabilities    \n",
    "        y_probs = cv_model.predict_proba(X_test)\n",
    "        y_probs = y_probs[:, 1]\n",
    "    \n",
    "        precision, recall, thresholds = precision_recall_curve(y_test, y_probs)\n",
    "\n",
    "        auc_scores.append(auc(recall, precision))\n",
    "        \n",
    "    print(f\"C:\" f\"{C:.3f}\")\n",
    "    print(f\"Balanced accuracy mean:\" f\"{np.mean(accuracy_scores):.3f}\")\n",
    "    print('Logistic: f1 score=%.3f auc score=%.3f' % (np.mean(f1_scores), np.mean(auc_scores)))    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "640a81c3",
   "metadata": {},
   "source": [
    "# ROC vs. Precision-Recall Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d12fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC curves should be used when there are roughly equal numbers of observations for each class.\n",
    "# Precision-Recall curves should be used when there is a moderate to large class imbalance.\n",
    "# https://machinelearningmastery.com/roc-curves-and-precision-recall-curves-for-classification-in-python/\n",
    "\n",
    "display = PrecisionRecallDisplay.from_estimator(\n",
    "    cv_model, X_test, y_test, name=\"LogisticRegression\")\n",
    "\n",
    "_ = display.ax_.set_title(\"2-class Precision-Recall curve\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c35f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC curve\n",
    "RocCurveDisplay.from_estimator(cv_model, X_test, y_test, name=\"LogisticRegression\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e63c034",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
